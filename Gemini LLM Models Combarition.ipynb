{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aba058a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-genai in c:\\users\\nirosh\\anaconda3\\envs\\cits5508\\lib\\site-packages (1.35.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\nirosh\\anaconda3\\envs\\cits5508\\lib\\site-packages (1.1.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\nirosh\\anaconda3\\envs\\cits5508\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: tabulate in c:\\users\\nirosh\\anaconda3\\envs\\cits5508\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in c:\\users\\nirosh\\anaconda3\\envs\\cits5508\\lib\\site-packages (from google-genai) (4.8.0)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in c:\\users\\nirosh\\anaconda3\\envs\\cits5508\\lib\\site-packages (from google-genai) (2.40.3)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in c:\\users\\nirosh\\anaconda3\\envs\\cits5508\\lib\\site-packages (from google-genai) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in c:\\users\\nirosh\\anaconda3\\envs\\cits5508\\lib\\site-packages (from google-genai) (2.11.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in c:\\users\\nirosh\\anaconda3\\envs\\cits5508\\lib\\site-packages (from google-genai) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in c:\\users\\nirosh\\anaconda3\\envs\\cits5508\\lib\\site-packages (from google-genai) (9.1.2)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in c:\\users\\nirosh\\anaconda3\\envs\\cits5508\\lib\\site-packages (from google-genai) (15.0.1)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in c:\\users\\nirosh\\anaconda3\\envs\\cits5508\\lib\\site-packages (from google-genai) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\nirosh\\anaconda3\\envs\\cits5508\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nirosh\\anaconda3\\envs\\cits5508\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nirosh\\anaconda3\\envs\\cits5508\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nirosh\\anaconda3\\envs\\cits5508\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\nirosh\\anaconda3\\envs\\cits5508\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\nirosh\\anaconda3\\envs\\cits5508\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\nirosh\\anaconda3\\envs\\cits5508\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\nirosh\\anaconda3\\envs\\cits5508\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\nirosh\\anaconda3\\envs\\cits5508\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\nirosh\\anaconda3\\envs\\cits5508\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\nirosh\\anaconda3\\envs\\cits5508\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\nirosh\\anaconda3\\envs\\cits5508\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\nirosh\\anaconda3\\envs\\cits5508\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\nirosh\\anaconda3\\envs\\cits5508\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\nirosh\\anaconda3\\envs\\cits5508\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nirosh\\anaconda3\\envs\\cits5508\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\nirosh\\anaconda3\\envs\\cits5508\\lib\\site-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nirosh\\anaconda3\\envs\\cits5508\\lib\\site-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\nirosh\\anaconda3\\envs\\cits5508\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U google-genai python-dotenv pandas tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6174fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEMINI_API_KEY: AIza...2-E8\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Change \"keys.env\" to \".env\" if that's your filename\n",
    "load_dotenv(\"keys.env\")\n",
    "\n",
    "def masked(v): \n",
    "    return v[:4] + \"...\" + v[-4:] if v and len(v) >= 8 else str(bool(v))\n",
    "\n",
    "print(\"GEMINI_API_KEY:\", masked(os.getenv(\"GEMINI_API_KEY\")))\n",
    "assert os.getenv(\"GEMINI_API_KEY\"), \"Missing GEMINI_API_KEY in keys.env/.env\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e56573a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 90\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 90\u001b[0m         q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m> \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m q\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquit\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[0;32m     92\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nirosh\\anaconda3\\envs\\cits5508\\Lib\\site-packages\\ipykernel\\kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nirosh\\anaconda3\\envs\\cits5508\\Lib\\site-packages\\ipykernel\\kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import sys\n",
    "\n",
    "# --- Setup ---\n",
    "client = genai.Client()\n",
    "MODEL = \"gemini-2.5-flash\"\n",
    "\n",
    "# Create a chat session (keeps history across turns)\n",
    "chat = client.chats.create(\n",
    "    model=MODEL,\n",
    "    config=types.GenerateContentConfig(\n",
    "        temperature=0.0,\n",
    "        max_output_tokens=128,\n",
    "        candidate_count=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "# --- Helpers ---\n",
    "def _extract_text_from_response(resp) -> str:\n",
    "    \"\"\"Pull full text from a non-streaming response.\"\"\"\n",
    "    if not getattr(resp, \"candidates\", None):\n",
    "        return \"\"\n",
    "    out = []\n",
    "    for cand in resp.candidates or []:\n",
    "        content = getattr(cand, \"content\", None)\n",
    "        parts = getattr(content, \"parts\", []) if content else []\n",
    "        for p in parts:\n",
    "            t = getattr(p, \"text\", None)\n",
    "            if t:\n",
    "                out.append(t)\n",
    "    return \"\".join(out)\n",
    "\n",
    "def _extract_text_from_event(event) -> str:\n",
    "    \"\"\"Pull any text from a streaming event.\"\"\"\n",
    "    out = []\n",
    "    for cand in getattr(event, \"candidates\", []) or []:\n",
    "        content = getattr(cand, \"content\", None)\n",
    "        parts = getattr(content, \"parts\", []) if content else []\n",
    "        for p in parts:\n",
    "            t = getattr(p, \"text\", None)\n",
    "            if t:\n",
    "                out.append(t)\n",
    "    return \"\".join(out)\n",
    "\n",
    "def _maybe_print_safety(event):\n",
    "    \"\"\"Show safety blocks if present.\"\"\"\n",
    "    fb = getattr(event, \"prompt_feedback\", None)\n",
    "    if not fb:\n",
    "        return\n",
    "    block = getattr(fb, \"block_reason\", None) or getattr(fb, \"block_reason_message\", None)\n",
    "    if block:\n",
    "        print(f\"\\n[blocked: {block}]\", flush=True)\n",
    "\n",
    "# --- Main ask function ---\n",
    "def ask(user_text: str):\n",
    "    \"\"\"Stream reply token by token; fallback to non-streaming if needed.\"\"\"\n",
    "    print(f\"\\nYou: {user_text}\")\n",
    "    print(\"Model:\", end=\" \", flush=True)\n",
    "\n",
    "    got_text = False\n",
    "    try:\n",
    "        for event in chat.send_message_stream(user_text):\n",
    "            chunk = _extract_text_from_event(event)\n",
    "            if chunk:\n",
    "                print(chunk, end=\"\", flush=True)\n",
    "                got_text = True\n",
    "            else:\n",
    "                _maybe_print_safety(event)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[stream error] {e}\", file=sys.stderr)\n",
    "\n",
    "    print()  # newline after stream\n",
    "\n",
    "    # fallback if nothing visible came out\n",
    "    if not got_text:\n",
    "        try:\n",
    "            resp = chat.send_message(user_text)\n",
    "            text = _extract_text_from_response(resp)\n",
    "            if text:\n",
    "                print(text)\n",
    "            else:\n",
    "                print(\"[no text returned; possibly safety-filtered or empty]\")\n",
    "        except Exception as e:\n",
    "            print(f\"[fallback error] {e}\")\n",
    "\n",
    "# --- Example REPL loop ---\n",
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        q = input(\"\\n> \")\n",
    "        if q.strip().lower() in {\"exit\", \"quit\"}:\n",
    "            break\n",
    "        ask(q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08a6d902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You: hi\n",
      "Model: Hi there! How can I help you today?\n",
      "\n",
      "You: iam doing real time convestation with ai project can you help me\n",
      "Model: \n",
      "[no text returned; possibly safety-filtered or empty]\n",
      "\n",
      "You: ...............................\n",
      "Model: \n",
      "[no text returned; possibly safety-filtered or empty]\n",
      "\n",
      "You: Hi there! How can I help you today?\n",
      "Model: \n",
      "[no text returned; possibly safety-filtered or empty]\n",
      "\n",
      "You: \n",
      "Model: \n",
      "It looks like you might have sent an empty message.\n",
      "\n",
      "Is there something you'd like to talk about or ask? I'm here to help!\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "import sys\n",
    "\n",
    "# ---------- Setup ----------\n",
    "client = genai.Client()\n",
    "MODEL = \"gemini-2.5-flash\"\n",
    "\n",
    "chat = client.chats.create(\n",
    "    model=MODEL,\n",
    "    config=types.GenerateContentConfig(\n",
    "        temperature=0.0,\n",
    "        max_output_tokens=128,\n",
    "        candidate_count=1,\n",
    "    )\n",
    ")\n",
    "\n",
    "# ---------- Robust extractors ----------\n",
    "def _parts_text(parts):\n",
    "    \"\"\"Join any available .text in a parts list; tolerate missing fields.\"\"\"\n",
    "    out = []\n",
    "    if not parts:\n",
    "        return \"\"\n",
    "    for p in parts:\n",
    "        t = getattr(p, \"text\", None)\n",
    "        if t:\n",
    "            out.append(t)\n",
    "    return \"\".join(out)\n",
    "\n",
    "def _extract_text_from_response(resp) -> str:\n",
    "    \"\"\"Non-streaming: safely extract all text from resp.\"\"\"\n",
    "    if resp is None:\n",
    "        return \"\"\n",
    "    cands = getattr(resp, \"candidates\", None) or []\n",
    "    out = []\n",
    "    for cand in cands:\n",
    "        content = getattr(cand, \"content\", None)\n",
    "        parts = getattr(content, \"parts\", None)\n",
    "        out.append(_parts_text(parts))\n",
    "    return \"\".join(out)\n",
    "\n",
    "def _extract_text_from_event(event) -> str:\n",
    "    \"\"\"Streaming: safely extract any text from a stream event.\"\"\"\n",
    "    if event is None:\n",
    "        return \"\"\n",
    "    cands = getattr(event, \"candidates\", None) or []\n",
    "    out = []\n",
    "    for cand in cands:\n",
    "        content = getattr(cand, \"content\", None)\n",
    "        parts = getattr(content, \"parts\", None)\n",
    "        out.append(_parts_text(parts))\n",
    "    return \"\".join(out)\n",
    "\n",
    "def _maybe_print_safety(event):\n",
    "    fb = getattr(event, \"prompt_feedback\", None)\n",
    "    if not fb:\n",
    "        return\n",
    "    # try a couple of common attribute names\n",
    "    reason = getattr(fb, \"block_reason\", None) or getattr(fb, \"block_reason_message\", None)\n",
    "    if reason:\n",
    "        print(f\"\\n[blocked: {reason}]\", flush=True)\n",
    "\n",
    "# ---------- Main: streaming with fallback ----------\n",
    "def ask(user_text: str):\n",
    "    \"\"\"Stream the reply; if stream yields no visible text, fallback to non-streaming.\"\"\"\n",
    "    print(f\"\\nYou: {user_text}\")\n",
    "    print(\"Model:\", end=\" \", flush=True)\n",
    "\n",
    "    got_text = False\n",
    "    try:\n",
    "        for event in chat.send_message_stream(user_text):\n",
    "            chunk = _extract_text_from_event(event)\n",
    "            if chunk:\n",
    "                print(chunk, end=\"\", flush=True)\n",
    "                got_text = True\n",
    "            else:\n",
    "                _maybe_print_safety(event)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[stream error] {e}\", file=sys.stderr)\n",
    "\n",
    "    print()  # newline after stream\n",
    "\n",
    "    # Fallback: call non-streaming once if nothing was printed\n",
    "    if not got_text:\n",
    "        try:\n",
    "            resp = chat.send_message(user_text)\n",
    "            text = _extract_text_from_response(resp)\n",
    "            if text:\n",
    "                print(text)\n",
    "            else:\n",
    "                print(\"[no text returned; possibly safety-filtered or empty]\")\n",
    "        except Exception as e:\n",
    "            print(f\"[fallback error] {e}\")\n",
    "\n",
    "# ---------- Optional: notebook-friendly helper ----------\n",
    "def ask_once(user_text: str) -> str:\n",
    "    \"\"\"Return the full text in one go (no streaming) â€” handy in notebooks.\"\"\"\n",
    "    try:\n",
    "        resp = chat.send_message(user_text)\n",
    "        return _extract_text_from_response(resp)\n",
    "    except Exception as e:\n",
    "        return f\"[error] {e}\"\n",
    "\n",
    "# ---------- REPL (comment out when using in notebooks) ----------\n",
    "if __name__ == \"__main__\":\n",
    "    while True:\n",
    "        q = input(\"\\n> \")\n",
    "        if q.strip().lower() in {\"exit\", \"quit\"}:\n",
    "            break\n",
    "        ask(q)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cits5508",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
